{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Densenet on NIH Chest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ef0657e6a818dbcc14d48bd3c885fac3d579fef"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as ticker\n",
    "sns.set_style('whitegrid')\n",
    "# %matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "#from generator import DataGenerator\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4899857bd75ea5b12305429d7611a182c3647f60"
   },
   "source": [
    "<h1> Data Preprocessing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "600d7039b60f31992a67b6ca924f60d2bce187b1"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\cxrdataset\\Data_Entry_2017.csv\")\n",
    "data = data[data['Patient Age'] < 100]  # removing datapoints which having age greater than 100\n",
    "\n",
    "# Adjust the path to match your actual directory structure\n",
    "data_image_paths = {os.path.basename(x): x for x in glob(os.path.join(r'D:\\cxrdataset', 'images_*', 'images', '*.png'))}\n",
    "print('Scans found:', len(data_image_paths), ', Total Headers', data.shape[0])\n",
    "\n",
    "# Map image paths to the DataFrame\n",
    "data['path'] = data['Image Index'].map(data_image_paths.get)\n",
    "\n",
    "# Check for missing paths\n",
    "missing_paths = data['path'].isnull().sum()\n",
    "print(f'Missing paths: {missing_paths}')\n",
    "\n",
    "# Ensure all paths are correctly assigned\n",
    "if missing_paths > 0:\n",
    "    print(\"Some image paths are missing. Please check the 'Image Index' values and the image directory.\")\n",
    "\n",
    "# Continue with the rest of the code\n",
    "data['Patient Age'] = data['Patient Age'].map(lambda x: int(x))\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c51e6353264ab9ec25e65fb2608f0174d370afc4"
   },
   "outputs": [],
   "source": [
    "data['Finding Labels'] = data['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
    "from itertools import chain\n",
    "all_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x)>0]\n",
    "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
    "for c_label in all_labels:\n",
    "    if len(c_label)>1: # leave out empty labels\n",
    "        data[c_label] = data['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "048e1c4bd4d0f05777660cdadad719ff6da4081d"
   },
   "outputs": [],
   "source": [
    "# keep at least 1000 cases\n",
    "MIN_CASES = 1000\n",
    "all_labels = [c_label for c_label in all_labels if data[c_label].sum()>MIN_CASES]\n",
    "print('Clean Labels ({})'.format(len(all_labels)), \n",
    "      [(c_label,int(data[c_label].sum())) for c_label in all_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f3404efcf52fae25b0cc4453a9bff8aefc52584"
   },
   "outputs": [],
   "source": [
    "# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n",
    "# weight is 0.04 + number of findings\n",
    "sample_weights = data['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\n",
    "sample_weights /= sample_weights.sum()\n",
    "data = data.sample(40000, weights=sample_weights)\n",
    "\n",
    "label_counts = data['Finding Labels'].value_counts()[:15]\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58c0a0a826f66189e32291e3a94156cb262e8cbf"
   },
   "outputs": [],
   "source": [
    "# creating vector of diseases\n",
    "data['disease_vec'] = data.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])\n",
    "data['disease_vec'] = data['disease_vec'].apply(lambda x: np.array(x, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e4d735b73ab9142020bf8629d7121b6183586d2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(data, \n",
    "                                   test_size = 0.20, \n",
    "                                   random_state = 2500,\n",
    "                                   stratify = data['Finding Labels'].map(lambda x: x[:4]))\n",
    "print('train', train_df.shape[0], 'test', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d300ee354d91b94ce210399c23452d11c48204a2"
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, \n",
    "                                   test_size = 0.10, \n",
    "                                   random_state = 2500,\n",
    "                                   stratify = train_df['Finding Labels'].map(lambda x: x[:4]))\n",
    "print('train', train_df.shape[0], 'valid', valid_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "93bbc10d73ba2a2872ed1c4e77fd0fa96a3574fa"
   },
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    df_gen = img_data_gen.flow_from_dataframe(\n",
    "        dataframe=in_df,\n",
    "        directory=None,\n",
    "        x_col=path_col,\n",
    "        y_col=y_col,\n",
    "        class_mode='raw',\n",
    "        **dflow_args\n",
    "    )\n",
    "    while True:\n",
    "        batch = next(df_gen)\n",
    "        yield batch[0], np.stack(batch[1]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4112847b0b6e3b9e0e51e99b13fc40508078b577"
   },
   "outputs": [],
   "source": [
    "from keras.applications import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cff7a4760c14a46c326809857d5fe43586d8b89"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "IMG_SIZE = (224, 224) \n",
    "core_idg_Densenet = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3159267661da66b28355b2638dd4e8ea54a73749"
   },
   "outputs": [],
   "source": [
    "train_gen = flow_from_dataframe(core_idg_Densenet, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 16)\n",
    "\n",
    "valid_gen = flow_from_dataframe(core_idg_Densenet, valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 32) # we can use much larger batches for evaluation\n",
    "# used a fixed dataset for evaluating the algorithm\n",
    "test_X, test_Y = next(flow_from_dataframe(core_idg_Densenet, \n",
    "                               test_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'disease_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 8000)) # one big batch\n",
    "# used a fixed dataset for final evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c977a4bc10afc97657fc6378e0820d29025f3da2"
   },
   "outputs": [],
   "source": [
    "t_x, t_y = next(train_gen)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0])\n",
    "    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n",
    "                             if n_score>0.5]))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a5041e979159828dec25b9c84208cb950db489d"
   },
   "outputs": [],
   "source": [
    "# Densenet model\n",
    "img_in = Input(t_x.shape[1:])              #input of model \n",
    "model = DenseNet121(include_top= False , # remove  the 3 fully-connected layers at the top of the network\n",
    "                weights='imagenet',      # pre train weight \n",
    "                input_tensor= img_in, \n",
    "                input_shape= t_x.shape[1:],\n",
    "                pooling ='avg') \n",
    "\n",
    "x = model.output  \n",
    "\n",
    "predictions = Dense(len(all_labels), activation=\"sigmoid\", name=\"predictions_3\")(x)    # fuly connected layer for predict class \n",
    "model = Model(inputs=img_in, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d17cdb65a9870604f262a37e20d548880c2b36d3"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[keras.metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc088ab9eea3b5e730541db2c7ee2a27eda4c203"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_gen, \n",
    "                                  steps_per_epoch=100,\n",
    "                                  validation_data = valid_gen,\n",
    "                                  validation_steps=50, \n",
    "                                  epochs = 100)\n",
    "model.save_weights('densenet_model_weights.keras')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c61128c4459261207014cd9962e1b9c1d8bff89e"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6975c0429ba4ffcbc47d8f26d449d34349812b13"
   },
   "outputs": [],
   "source": [
    "# look at how often the algorithm predicts certain diagnoses \n",
    "for c_label, p_count, t_count in zip(all_labels, \n",
    "                                     100*np.mean(y_pred,0), \n",
    "                                     100*np.mean(test_Y,0)):\n",
    "    print('%s: actual: %2.2f%%, predicted: %2.2f%%' % (c_label, t_count, p_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4a61c95f401765a34122fb02852e8814e8c0197"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, c_label) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), y_pred[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('trained_Densenet.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe8f7bde78386be9a6fc19acf895a7b00388726b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(test_Y.astype(int), y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
